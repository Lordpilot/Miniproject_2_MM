---
title: "MM2-eksamen"
author: "Gruppe 1.211"
date: "28/10/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(gRbase)
library(gRain)
```

We have the dataset ChestSim1000
```{r}
data(chestSim1000, package="gRbase")
head(chestSim1000) # our data
length(chestSim1000[,1]) # our data consists of 1000 observations
```

This is a hyphotetical Chest Clinic problem, by Lauritzen and Spiegelhalter. (ref til https://arxiv.org/pdf/1301.7394.pdf)

Here is a short explanation of the variables in the dataset.

* asia $\rightarrow$ subject has visited asia
* tub $\rightarrow$ subject has tuberculosis
* smoke $\rightarrow$ subject is a smoker
* lung $\rightarrow$ subject has lung cancer
* bronc $\rightarrow$ subject has bronchitis
* either $\rightarrow$ subject has either tuberculosis or lungcancer
* xray $\rightarrow$ subject has positive X-ray
* dysp $\rightarrow$ Subject has dyspnoea

Shortness-of-breath (dyspnoea) may be due to tuberculosis, lung cancer, bronchitis, none of them, or more than one of them. A recent visit to Asia increases the chances of tuberculosis, while smoking is known to be a risk factor for both lung cancer and bronchitis. The results of a single chest X-ray do not discriminate between lung cancer and tuberculosis, as does neither the presence nor absence of dyspnoea. (citat direkte sat ind fra https://arxiv.org/pdf/1301.7394.pdf)


Now consider the following excerpt from the chest clinic examples:
```{r}
dg1 <- dag(~ S + L|S + X|L:S + B|S + D|L:B)
plot(dg1) # example of a bayesian network
```



# Exercise 1 
Extract the necessary CPT's from data, and construct the Bayesian network.

# Answer
Here let $V = \{Asia, Tub, Smoke, Lung, Either, Bronc, Xray, Dysp\}=\{a,t,s,l,e,x,d\}$ denote the total number of nodes.
Each nodes represent a binary level $\{yes, no\}$.

For each node $v$ and its parents $pa(v)$ there is a conditional distribution $P(v\mid pa(v))$.
For more then one parent node, for example two, we write $P(v_1\mid v_2,v_3)$

By inspection of the graph above, we observe that we need $P(S)$, $P(B|S)$, $P(D|B,L)$, $P(L|S)$ and $P(X|L,S)$ for the joint distribution.

```{r}
n.cis <- xtabs(~smoke + lung + xray + bronc + dysp, data = chestSim1000) # An overview of the data
as.data.frame(n.cis) #Shows frequency of each combination
```

Now the CPTs for the probabilities

```{r}
p.s <- tabDist(n.cis, marg = ~ smoke);p.s #P(S)
```

```{r}
cpt.bs <- tabDist(n.cis, marg = ~ bronc, cond = ~ smoke) #P(B|S)
cpt.bs %>% ftable(row.vars = "bronc")
```

```{r}
cpt.dbl <- tabDist(n.cis, marg = ~ dysp, cond = ~ bronc:lung) #P(D|B,L)
cpt.dbl %>% ftable(row.vars = "dysp")
```

```{r}
cpt.ls <- tabDist(n.cis, marg = ~ lung, cond = ~ smoke) #P(L|S)
cpt.ls %>% ftable(row.vars = "lung")
```

```{r}
cpt.xls <- tabDist(n.cis, marg = ~ xray, cond = ~ lung:smoke) #P(X|L,S)
cpt.xls %>% ftable(row.vars = "xray")
```

```{r}
cptlist <- compileCPT(list(p.s, cpt.ls, cpt.xls, cpt.bs, cpt.dbl))
grn1 <- grain(cptlist)
grn1c <- propagate(grn1)
plot1=compile(grn1);plot1 
plot(plot1$dag)
```



The DAG shows the factorization of the joint probability function given by 
$$P(V ) = P(s) P(l|s) P(b|s) P(d|l,b)    P(x|l,s)$$
More generally written we have that a DAG with $V$ nodes allows us to construct a joint distribution by combining univariante condiional distribution by 
$$P(V)=\prod_{v}P(v\mid pa(v))$$

# Exercise 2
What does information about "dysp" tell us about "smoke", i.e. what is the conditional distribution of "smoke" given "dysp"?

# Answer
What we are looking for here is a simple conditional distribution of $p(v\mid pa(v))$ where $v$ is a node and $pa(v)$ denotes the parents node

```{r}
querygrain(grn1c, nodes = c("smoke", "dysp"), type ="conditional") %>%
  ftable(row.vars = "smoke")
#given that that the person has dysp or not, gives respectively 61% or 36% chance of the person to be a smoker.
```

```{r}
querygrain(grn1, nodes = c("smoke", "dysp"), type ="conditional") #hvad er forskellen på når funktionen propagate er brugt? SLETTES MÅSKE
```




# Exercise 3
If we know "smoke", what does additional infomration about "bronc" tell us about "lung"? That is, what is the conditional distribution of "lung" given smoke", and what is the conditional distribution of "lung" given "smoke" and "bronc"?

# Answer
The first distribution is the simple conditional distribution as we know it $p(v\mid pa(v))$ where as the second distribution is a little more complex $p(v_1\mid v_2, v_3)$ where $pa(v_1)=\{v_2, v_3\}$.

```{r}
querygrain(grn1c, nodes = c("lung","smoke"), type ="conditional") %>%
  ftable(row.vars = "lung")
```

```{r}
querygrain(grn1c, nodes = c("lung","smoke", "bronc"), type ="conditional") %>%
  ftable(row.vars = "lung")
```
We see that additional information about bronc does not have any influence on lung. This suits the DAG of the bayesian network.



# Exercise 4
If we know "smoke" and "dysp", what does additional information about "bronc" tell us about "lung"?

# Answer
Here we look at $P(v_1\mid v_2, v_3)$ where $pa(v_1)=\{v_2, v_3\}$ for "smoke" and "dysp" and  $P(v_1\mid v_2, v_3, v_4)$ where $pa(v)=\{v_2, v_3, v_4\}$ for "smoke", "dysp" and "bronc".

```{r}
querygrain(grn1c, nodes = c("lung","smoke", "dysp"), type ="conditional") %>%
  ftable(row.vars = "lung")
```

```{r}
querygrain(grn1c, nodes = c("lung","smoke","dysp", "bronc"), type ="conditional") %>%
  ftable(row.vars = "lung")
```

This exercise is different from exercise 3, as dysp is now a factor, and lung and bronc are not independent given dysp. This is called common effect. 

If we know dysp and bronc are true, there is a smaller chance that lung is true. In other words, if you have dysp, caused by bronc, then it is unlikely that the patient has lung cancer.



# Exercise 5
Sketch the message passing algorithm for finding clique marginals for this specific example

```{r}
library(gRbase)
library(gRain)
```


# Answer

```{r}
# data from exercise 1
plot1=compile(grain(cptlist)) #turns CPT into a graphical independent network and the compiles them
plot(plot1$dag) # the plot containing the Directed Acyclic Graph
plot(moralize(plot1$dag)) # marrying parents and removing directions produces the Moral Graph 
```

Note here that $P(V)$ has interactions only among neighbours of the undirected moral graph. To understand this let $q(v_2,v_1)$ denote a interaction function from point $v_1$ to $v_2$ without direction so for our data i exercise 1 we have 

$$P(V) = P(a) p(t|a) P(s) P(l|s) P(b|s) P(e|t,l) P(d|e,b) P(x|e)\\
= q(a) q(t,a) q(s) q(l,s) q(b,s) q(e,t,l) q(d,e,b) q(x,e)$$

Then merging the q-functions that are contained in large q-functions we get

$$P(V)= q(t,a) q(l,s) q(b,s) q(e,t,l) q(d,e,b) q(x,e)$$
These are then the clique marginals in the sense that $P(l,s)=q(l,s)$ and so forth, these clique marginls can be extracted directly
```{r}
lung.smoke1 <- xtabs(~lung+smoke, chestSim1000); lung.smoke1
```


The q-function $q(e,t,l)$ is what creats the new interaction between $t$ and $l$.

```{r}
# data from exercise 2
#plot2=compile(grain(CPT.list2))
#plot(plot2$dag)
#plot(moralize(plot2$dag))
```

Here we have 
$$P(V)=P(d) P(s\mid d)\\
= q(d) q(s, d)$$
then merging gives
$$P(V)=q(s, d)$$

```{r}
# data from exercise 3
#plot3=compile(grain(CPT.list3))
#plot(plot3$dag)
#plot(moralize(plot3$dag))
```

Here we have 
$$P(V)=P(s) P(b) P(l\mid s, b)\\
= q(s) q(b) q(l,s,b)$$
Merging gives
$$P(V)=q(l,s,b)$$

```{r}
# data from exercise 4
#plot4=compile(grain(CPT.list4))
#plot(plot4$dag)
#plot(moralize(plot4$dag))
```

Here we have 
$$P(V)=P(s) P(d) P(b) P(l\mid s,d,b)\\
=q(s) q(d) q(b) q(l,s,d,b)$$
Mergining gives
$$P(V)=q(l,s,d,b)$$

# Part 2, initial work
Consider the "cad" data in "gRbase". There are two dataset: "cad1" which is complete and "cad2" which has missing values here and there.
```{r}
library(graph)
library(Rgraphviz)
library(RBGL)
library(gRbase)
library(gRain)
library(bnlearn)
library(magrittr)
data(cad1, package="gRbase")
names(cad1)
use <- c("Sex", "CAD", "Inherit", "Smoker", "Hyperchol", "Heartfail", "AMI")
dat1 <- cad1[, use] # Loader data
```

# Exercise 6
Use the hill climbing algorithm function from the "bnlearn" package to estimate different Bayesian networks based on data "cad1". see R script provided elsewhere.

# Answer
```{r}
## Start search from empty graph
mm1 <- hc(dat1)
mm1
## Start search from complete graph
sat <-random.graph(use, prob = 1) # Generate empty or random directed acyclic graphs from a given set of "nodes"
mm2 <- hc(dat1, start=sat)
mm2
# Now we have the two generated graphs
par(mfrow=c(1,2))
plot(mm1)
plot(mm2)
## Create Bayesian network
bn1 <- as.grain(bn.fit(mm1, dat1)) # This will be the focus point
bn2 <- as.grain(bn.fit(mm2, dat1))
```

# Exercise 7
Predict the value of the CAD variable in the dataset "cad1" for each of the models you find. Predict the value of the CAD variable in the dataset "cad2" for each of the models you find. Is it most appropriate to evaluate the models based on "cad1" or "cad2".

# Answer
```{r}
## Predict data
## Sample 40 random rows
set.seed(1213)
userow <- sample(nrow(dat1), 40) # Take 40 observations out of dataset
wdat1 <- dat1[userow,] # Use them
pred1 <- predict(bn1, newdata=wdat1, response="CAD") # This will be the focus
pred2 <- predict(bn2, newdata=wdat1, response="CAD")
table(wdat1$CAD, pred1$pred$CAD) # The real dataset vs. the predicted for hc method
table(wdat1$CAD, pred2$pred$CAD) 
## Procent 
table(wdat1$CAD, pred1$pred$CAD)/40*100 
table(wdat1$CAD, pred2$pred$CAD)/40*100
#' Notice:
#' 
#' Prediction based on same data as we used for fitting / model search
#' is cheating. Use cad2 data instead.
#'
#' What are the misclassification errors under various models?
#'
#' Which misclassifications are the most serious ones?
#' 
#' Using cad2:
data(cad2, package="gRbase")
names(cad2)
use <- c("Sex", "CAD", "Inherit", "Smoker", "Hyperchol", "Heartfail", "AMI")
dat2 <- cad2[, use]
## Sample 40 random rows
set.seed(1213)
userow <- sample(nrow(dat2), 40) # Pick 40 observations
wdat2 <- dat2[userow,]
pred3 <- predict(bn1, newdata=wdat2, response="CAD") 
pred4 <- predict(bn2, newdata=wdat2, response="CAD")
table(wdat2$CAD, pred3$pred$CAD)
table(wdat2$CAD, pred4$pred$CAD)
```

# Exercise 8
Compute the misclassification probabilities for persons with CAD and persons without CAD for each model. Which misclassification is most severe?

# Answer
```{r}
## Procenter
table(wdat2$CAD, pred3$pred$CAD)/40*100
table(wdat2$CAD, pred4$pred$CAD)/40*100
```

Type 1 error: to reject, while the patient is positive

Type 2 error: to accept, while the patient is negative

It can be seen that a type 1 and type 2 error is the same for "pred4" for cad2"
 
For "pred3" for "cad2" there is 15% type 1 error and 10% type 2 error

If the treatment is hard on the patients, a type 2 error would be problematic, however introducing multiple test would avoid this

Type 1 errors are "the most servere" since the patient wouldn't get the treatment

this can lead to large consequences for the patient.
