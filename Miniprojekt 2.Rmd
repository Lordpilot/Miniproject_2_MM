---
title: "MM2-eksamen"
author: "Gruppe 1.211"
date: "28/10/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(gRbase)
library(gRain)
```

We have the dataset ChestSim1000
```{r}
data(chestSim1000, package="gRbase")
head(chestSim1000) # our data
length(chestSim1000[,1]) # our data consists of 1000 observations
```

This is a hyphotetical Chest Clinic problem, by Lauritzen and Spiegelhalter. (ref til https://arxiv.org/pdf/1301.7394.pdf)

Here is a short explanation of the variables in the dataset.

* asia $\rightarrow$ subject has visited asia
* tub $\rightarrow$ subject has tuberculosis
* smoke $\rightarrow$ subject is a smoker
* lung $\rightarrow$ subject has lung cancer
* bronc $\rightarrow$ subject has bronchitis
* either $\rightarrow$ subject has either tuberculosis or lungcancer
* xray $\rightarrow$ subject has positive X-ray
* dysp $\rightarrow$ Subject has dyspnoea

Shortness-of-breath (dyspnoea) may be due to tuberculosis, lung cancer, bronchitis, none of them, or more than one of them. A recent visit to Asia increases the chances of tuberculosis, while smoking is known to be a risk factor for both lung cancer and bronchitis. The results of a single chest X-ray do not discriminate between lung cancer and tuberculosis, as does neither the presence nor absence of dyspnoea. (citat direkte sat ind fra https://arxiv.org/pdf/1301.7394.pdf)

```{r}
dg1 <- dag(~ S + L|S + X|L:S + B|S + D|L:B)
plot(dg1) # example of a bayesian network
```



# Exercise 1 
Extract the necessary CPT's from data, and construct the Bayesian network.

# Answer
Here let $V = \{Asia, Tub, Smoke, Lung, Either, Bronc, Xray, Dysp\}=\{a,t,s,l,e,x,d\}$ denote the total number of nodes.
Each nodes represent a binary level $\{yes, no\}$.

For each node $v$ and its parents $pa(v)$ there is a conditional distribution $P(v\mid pa(v))$.
For more then one parent node, for example two, we write $P(v_1\mid v_2,v_3)$

```{r} 
library(gRain)
asia1 <- xtabs(~asia, chestSim1000); asia1 #putting observations together
tub.asia1 <- xtabs(~tub+asia, chestSim1000); tub.asia1 # counting tub given asia
smoke1 <- xtabs(~smoke, chestSim1000); smoke1
lung.smoke1 <- xtabs(~lung+smoke, chestSim1000); lung.smoke1
bronc.smoke1 <- xtabs(~bronc+smoke, chestSim1000); bronc.smoke1
either.lung.tub1 <- xtabs(~either+lung+tub, chestSim1000); either.lung.tub1
xray.either1 <- xtabs(~xray+either, chestSim1000); xray.either1
dysp.bronc.either1 <- xtabs(~dysp+bronc+either, chestSim1000); dysp.bronc.either1
# Constructing the conditional probability tables
asia1 <-  as.parray(asia1, normalize="first"); asia1 
tub.asia1 <-  as.parray(tub.asia1, normalize="first"); tub.asia1 
smoke1 <-  as.parray(smoke1, normalize="first"); smoke1
lung.smoke1 <-  as.parray(lung.smoke1, normalize="first"); lung.smoke1
bronc.smoke1 <-  as.parray(bronc.smoke1, normalize="first"); bronc.smoke1
either.lung.tub1 <-  as.parray(either.lung.tub1, normalize="first"); either.lung.tub1
  ftable(either.lung.tub1, row.vars = 1) #ftable helps us read the CPT when we have more the two variables.
xray.either1 <-  as.parray(xray.either1, normalize="first"); xray.either1
dysp.bronc.either1 <-  as.parray(dysp.bronc.either1, normalize="first"); dysp.bronc.either1
  ftable(dysp.bronc.either1, row.vars = 1)
CPT.list1 <- compileCPT(list(asia1,tub.asia1,smoke1,lung.smoke1,bronc.smoke1,either.lung.tub1,xray.either1,dysp.bronc.either1))
CPT.list1 # overview of all CPT's
# construct the Bayesian network
plot1=compile(grain(CPT.list1));plot1 
plot(plot1$dag) # the Directed Acyclic Graph
```

The DAG shows the factorization of the joint probability function given by 
$$P(V ) = P(a) P(t|a) P(s) P(l|s) P(b|s) P(e|t,l) P(d|e,b) P(x|e)$$
More generally written we have that a DAG with $V$ nodes allowsus to construct a joint distribution by combining univariante condiional distribution by 
$$P(V)=\prod_{v}P(v\mid pa(v)$$
We see here that for $P(V)$ representet by a table would be a table with $2^{8}=256$ entries

# Exercise 2
What does information about "dysp" tell us about "smoke", i.e. what is the conditional distribution of "smoke" given "dysp"?

# Answer
What we are looking for here is a simple conditional distribution of $p(v\mid pa(v))$ where $v$ is a node and $pa(v)$ denotes the parents node

```{r}
dysp1 <- xtabs(~dysp, chestSim1000); dysp1 #counting the number of observations for dysp
smoke.dysp1 <- xtabs(~smoke+dysp, chestSim1000); smoke.dysp1  # counting smoke given dysp
# Constructing the conditional probability tables
dysp1 <-  as.parray(dysp1, normalize="first"); dysp1
smoke.dysp1 <-  as.parray(smoke.dysp1, normalize="first"); smoke.dysp1
CPT.list2 <- compileCPT(list(dysp1,smoke.dysp1)) #creating our CPT list
CPT.list2 # overview of CPT's
```

# Exercise 3
If we know "smoke", what does additional infomration about "bronc" tell us about "lung"? That is, what is the conditional distribution of "lung" given smoke", and what is the conditional distribution of "lung" given "smoke" and "bronc"?

# Answer
The first distribution is the simple conditional distribution as we know it $p(v\mid pa(v))$ where as the second distribution is intreast is more challenging $p(v_1\mid v_2, v_3)$ where $pa(v)=\{v_2, v_3\}$.

```{r}
smoke1 <- xtabs(~smoke, chestSim1000); smoke1 # counting smoke
bronc1 <- xtabs(~bronc, chestSim1000); bronc1 # counting bronc
lung.smoke1 <- xtabs(~lung+smoke, chestSim1000); lung.smoke1 # counting lung given smoke
lung.smoke.bronc1 <- xtabs(~lung+smoke+bronc, chestSim1000); lung.smoke.bronc1 # counting smoke given smoke and bronc 
  ftable(lung.smoke.bronc1, row.vars = 1) #for CPT's of more then two variables
# Constructing the conditional probability tables
smoke1 <-  as.parray(smoke1, normalize="first"); smoke1
bronc1 <-  as.parray(bronc1, normalize="first"); bronc1
lung.smoke1 <-  as.parray(lung.smoke1, normalize="first"); lung.smoke1
lung.smoke.bronc1 <-  as.parray(lung.smoke.bronc1, normalize="first"); lung.smoke.bronc1
CPT.list3 <- compileCPT(list(smoke1,bronc1, lung.smoke.bronc1)) #creating our CPT's note lunge is included two times so we use the largest
CPT.list3 # overview
```

# Exercise 4
If we know "smoke" and "dysp", what does additional information about "bronc" tell us about "lung"?

# Answer
Here we look at $P(v_1\mid v_2, v_3)$ where $pa(v)=\{v_2, v_3\}$ for "smoke" and "dysp" and  $P(v_1\mid v_2, v_3, v_4)$ where $pa(v)=\{v_2, v_3, v_4\}$ for "smoke", "dysp" and "bronc".

```{r}
smoke1 <- xtabs(~smoke, chestSim1000); smoke1 #counting smoke
dysp1 <- xtabs(~dysp, chestSim1000); dysp1
bronc1 <- xtabs(~bronc, chestSim1000); bronc1
lung.smoke.dysp1 <- xtabs(~lung+smoke+dysp, chestSim1000); lung.smoke.dysp1
lung.smoke.dysp.bronc1 <- xtabs(~lung+smoke+dysp+bronc, chestSim1000);lung.smoke.dysp.bronc1
# Constructing the conditional probability tables
smoke1 <-  as.parray(smoke1, normalize="first"); smoke1
dysp1 <-  as.parray(dysp1, normalize="first"); dysp1
bronc1 <-  as.parray(bronc1, normalize="first"); bronc1
lung.smoke.dysp1 <-  as.parray(lung.smoke.dysp1, normalize="first"); lung.smoke.dysp1
  ftable(lung.smoke.dysp1, row.vars = 1) #pretty verison
lung.smoke.dysp.bronc1 <-  as.parray(lung.smoke.dysp.bronc1, normalize="first"); lung.smoke.dysp.bronc1
  ftable(lung.smoke.dysp.bronc1, row.vars = 1) #pretty verison
CPT.list4 <- compileCPT(list(smoke1,dysp1,bronc1,lung.smoke.dysp.bronc1)) #creating CPT's list again we use the largest model to avoid repeating nodes
CPT.list4 # overview
```

# Exercise 5
Sketch the message passing algorithm for finding clique marginals for this specific example

```{r}
library(gRbase)
library(gRain)
```


# Answer

```{r}
# data from exercise 1
plot1=compile(grain(CPT.list1)) #turns CPT into a graphical independent network and the compiles them
plot(plot1$dag) # the plot containing the Directed Acyclic Graph
plot(moralize(plot1$dag)) # marrying parents and removing directions produces the Moral Graph 
```

Note here that $P(V)$ has interactions only among neighbours of the undirected moral graph. To understand this let $q(v_2,v_1)$ denote a interaction function from point $v_1$ to $v_2$ without direction so for our data i exercise 1 we have 

$$P(V) = P(a) p(t|a) P(s) P(l|s) P(b|s) P(e|t,l) P(d|e,b) P(x|e)\\
= q(a) q(t,a) q(s) q(l,s) q(b,s) q(e,t,l) q(d,e,b) q(x,e)$$

Then merging the q-functions that are contained in large q-functions we get

$$P(V)= q(t,a) q(l,s) q(b,s) q(e,t,l) q(d,e,b) q(x,e)$$
These are then the clique marginals in the sense that $P(l,s)=q(l,s)$ and so forth, these clique marginls can be extracted directly
```{r}
lung.smoke1 <- xtabs(~lung+smoke, chestSim1000); lung.smoke1
```


The q-function $q(e,t,l)$ is what creats the new interaction between $t$ and $l$.

```{r}
# data from exercise 2
plot2=compile(grain(CPT.list2))
plot(plot2$dag)
plot(moralize(plot2$dag))
```

Here we have 
$$P(V)=P(d) P(s\mid d)\\
= q(d) q(s, d)$$
then merging gives
$$P(V)=q(s, d)$$

```{r}
# data from exercise 3
plot3=compile(grain(CPT.list3))
plot(plot3$dag)
plot(moralize(plot3$dag))
```

Here we have 
$$P(V)=P(s) P(b) P(l\mid s, b)\\
= q(s) q(b) q(l,s,b)$$
Merging gives
$$P(V)=q(l,s,b)$$

```{r}
# data from exercise 4
plot4=compile(grain(CPT.list4))
plot(plot4$dag)
plot(moralize(plot4$dag))
```

Here we have 
$$P(V)=P(s) P(d) P(b) P(l\mid s,d,b)\\
=q(s) q(d) q(b) q(l,s,d,b)$$
Mergining gives
$$P(V)=q(l,s,d,b)$$

# Part 2, initial work
Consider the "cad" data in "gRbase". There are two dataset: "cad1" which is complete and "cad2" which has missing values here and there.
```{r}
library(graph)
library(Rgraphviz)
library(RBGL)
library(gRbase)
library(gRain)
library(bnlearn)
library(magrittr)
data(cad1, package="gRbase")
names(cad1)
use <- c("Sex", "CAD", "Inherit", "Smoker", "Hyperchol", "Heartfail", "AMI")
dat1 <- cad1[, use] # Loader data
```

# Exercise 6
Use the hill climbing algorithm function from the "bnlearn" package to estimate different Bayesian networks based on data "cad1". see R script provided elsewhere.

# Answer
```{r}
## Start search from empty graph
mm1 <- hc(dat1)
mm1
## Start search from complete graph
sat <-random.graph(use, prob = 1) # Generate empty or random directed acyclic graphs from a given set of "nodes"
mm2 <- hc(dat1, start=sat)
mm2
# Now we have the two generated graphs
par(mfrow=c(1,2))
plot(mm1)
plot(mm2)
## Create Bayesian network
bn1 <- as.grain(bn.fit(mm1, dat1)) # This will be the focus point
bn2 <- as.grain(bn.fit(mm2, dat1))
```

# Exercise 7
Predict the value of the CAD variable in the dataset "cad1" for each of the models you find. Predict the value of the CAD variable in the dataset "cad2" for each of the models you find. Is it most appropriate to evaluate the models based on "cad1" or "cad2".

# Answer
```{r}
## Predict data
## Sample 40 random rows
set.seed(1213)
userow <- sample(nrow(dat1), 40) # Take 40 observations out of dataset
wdat1 <- dat1[userow,] # Use them
pred1 <- predict(bn1, newdata=wdat1, response="CAD") # This will be the focus
pred2 <- predict(bn2, newdata=wdat1, response="CAD")
table(wdat1$CAD, pred1$pred$CAD) # The real dataset vs. the predicted for hc method
table(wdat1$CAD, pred2$pred$CAD) 
## Procent 
table(wdat1$CAD, pred1$pred$CAD)/40*100 
table(wdat1$CAD, pred2$pred$CAD)/40*100
#' Notice:
#' 
#' Prediction based on same data as we used for fitting / model search
#' is cheating. Use cad2 data instead.
#'
#' What are the misclassification errors under various models?
#'
#' Which misclassifications are the most serious ones?
#' 
#' Using cad2:
data(cad2, package="gRbase")
names(cad2)
use <- c("Sex", "CAD", "Inherit", "Smoker", "Hyperchol", "Heartfail", "AMI")
dat2 <- cad2[, use]
## Sample 40 random rows
set.seed(1213)
userow <- sample(nrow(dat2), 40) # Pick 40 observations
wdat2 <- dat2[userow,]
pred3 <- predict(bn1, newdata=wdat2, response="CAD") 
pred4 <- predict(bn2, newdata=wdat2, response="CAD")
table(wdat2$CAD, pred3$pred$CAD)
table(wdat2$CAD, pred4$pred$CAD)
```

# Exercise 8
Compute the misclassification probabilities for persons with CAD and persons without CAD for each model. Which misclassification is most severe?

# Answer
```{r}
## Procenter
table(wdat2$CAD, pred3$pred$CAD)/40*100
table(wdat2$CAD, pred4$pred$CAD)/40*100
```

Type 1 error: to reject, while the patient is positive

Type 2 error: to accept, while the patient is negative

It can be seen that a type 1 and type 2 error is the same for "pred4" for cad2"
 
For "pred3" for "cad2" there is 15% type 1 error and 10% type 2 error

If the treatment is hard on the patients, a type 2 error would be problematic, however introducing multiple test would avoid this

Type 1 errors are "the most servere" since the patient wouldn't get the treatment

this can lead to large consequences for the patient.
